# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19ckNrWtQLcXaPzqHSc0N_1cflRVL_bT2
"""

import pandas as pd
url = 'copied_raw_GH_link'
df1 = pd.read_csv("https://drive.google.com/uc?export=download&id=1eWeeYlxNatpXQSsiFwQg2HJeYCTJNj9Z")

df1.head()

df1.info()

import numpy as np
# No missing values
predictors = ["interest", "vacancy", "cpi", "price", "value", "adj_price", "adj_value"]
target = "next_quarter"

# Cleaning the data and applying Standard scaler on the predictors

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df1 = df1.ffill() # just for making the code scalable
df1[predictors] = scaler.fit_transform(df1[predictors])
df1[target] = (df1[target] - df1[target].min()) // 1000

# Now splitting the data into train, test, and validation

all_splits={}
split_data=np.split(df1,[int(.7*len(df1)),int(.85*len(df1))])
splits=[[d[predictors].to_numpy(),d[target].to_numpy()] for d in split_data]
splits
for split_name, split in zip(["train", "validation", "test"],splits):
  all_splits[split_name] = {"x": split[0], "target": split[1]}

split_data = all_splits

(split_data['train']['x'])

!pip install torch
import torch

# Convert the numpy arrays to torch tensors
train_x = torch.from_numpy(split_data['train']['x'])
train_y = torch.from_numpy(split_data['train']['target'])

train_x

train_y

